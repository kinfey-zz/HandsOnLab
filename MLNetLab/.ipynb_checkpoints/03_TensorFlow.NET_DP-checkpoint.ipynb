{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\r\n",
       "<div>\r\n",
       "    <div id='dotnet-interactive-this-cell-8608.Microsoft.DotNet.Interactive.Http.HttpPort' style='display: none'>\r\n",
       "        The below script needs to be able to find the current output cell; this is an easy method to get it.\r\n",
       "    </div>\r\n",
       "    <script type='text/javascript'>\r\n",
       "async function probeAddresses(probingAddresses) {\r\n",
       "    function timeout(ms, promise) {\r\n",
       "        return new Promise(function (resolve, reject) {\r\n",
       "            setTimeout(function () {\r\n",
       "                reject(new Error('timeout'))\r\n",
       "            }, ms)\r\n",
       "            promise.then(resolve, reject)\r\n",
       "        })\r\n",
       "    }\r\n",
       "\r\n",
       "    if (Array.isArray(probingAddresses)) {\r\n",
       "        for (let i = 0; i < probingAddresses.length; i++) {\r\n",
       "\r\n",
       "            let rootUrl = probingAddresses[i];\r\n",
       "\r\n",
       "            if (!rootUrl.endsWith('/')) {\r\n",
       "                rootUrl = `${rootUrl}/`;\r\n",
       "            }\r\n",
       "\r\n",
       "            try {\r\n",
       "                let response = await timeout(1000, fetch(`${rootUrl}discovery`, {\r\n",
       "                    method: 'POST',\r\n",
       "                    cache: 'no-cache',\r\n",
       "                    mode: 'cors',\r\n",
       "                    timeout: 1000,\r\n",
       "                    headers: {\r\n",
       "                        'Content-Type': 'text/plain'\r\n",
       "                    },\r\n",
       "                    body: probingAddresses[i]\r\n",
       "                }));\r\n",
       "\r\n",
       "                if (response.status == 200) {\r\n",
       "                    return rootUrl;\r\n",
       "                }\r\n",
       "            }\r\n",
       "            catch (e) { }\r\n",
       "        }\r\n",
       "    }\r\n",
       "}\r\n",
       "\r\n",
       "function loadDotnetInteractiveApi() {\r\n",
       "    probeAddresses([\"http://172.25.119.180:1024/\", \"http://127.0.0.1:1024/\"])\r\n",
       "        .then((root) => {\r\n",
       "        // use probing to find host url and api resources\r\n",
       "        // load interactive helpers and language services\r\n",
       "        let dotnetInteractiveRequire = require.config({\r\n",
       "        context: '8608.Microsoft.DotNet.Interactive.Http.HttpPort',\r\n",
       "                paths:\r\n",
       "            {\r\n",
       "                'dotnet-interactive': `${root}resources`\r\n",
       "                }\r\n",
       "        }) || require;\r\n",
       "\r\n",
       "            window.dotnetInteractiveRequire = dotnetInteractiveRequire;\r\n",
       "\r\n",
       "            window.configureRequireFromExtension = function(extensionName, extensionCacheBuster) {\r\n",
       "                let paths = {};\r\n",
       "                paths[extensionName] = `${root}extensions/${extensionName}/resources/`;\r\n",
       "                \r\n",
       "                let internalRequire = require.config({\r\n",
       "                    context: extensionCacheBuster,\r\n",
       "                    paths: paths,\r\n",
       "                    urlArgs: `cacheBuster=${extensionCacheBuster}`\r\n",
       "                    }) || require;\r\n",
       "\r\n",
       "                return internalRequire\r\n",
       "            };\r\n",
       "        \r\n",
       "            dotnetInteractiveRequire([\r\n",
       "                    'dotnet-interactive/dotnet-interactive'\r\n",
       "                ],\r\n",
       "                function (dotnet) {\r\n",
       "                    dotnet.init(window);\r\n",
       "                },\r\n",
       "                function (error) {\r\n",
       "                    console.log(error);\r\n",
       "                }\r\n",
       "            );\r\n",
       "        })\r\n",
       "        .catch(error => {console.log(error);});\r\n",
       "    }\r\n",
       "\r\n",
       "// ensure `require` is available globally\r\n",
       "if ((typeof(require) !==  typeof(Function)) || (typeof(require.config) !== typeof(Function))) {\r\n",
       "    let require_script = document.createElement('script');\r\n",
       "    require_script.setAttribute('src', 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js');\r\n",
       "    require_script.setAttribute('type', 'text/javascript');\r\n",
       "    \r\n",
       "    \r\n",
       "    require_script.onload = function() {\r\n",
       "        loadDotnetInteractiveApi();\r\n",
       "    };\r\n",
       "\r\n",
       "    document.getElementsByTagName('head')[0].appendChild(require_script);\r\n",
       "}\r\n",
       "else {\r\n",
       "    loadDotnetInteractiveApi();\r\n",
       "}\r\n",
       "\r\n",
       "    </script>\r\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><div></div><div><strong>Installed Packages</strong><ul><li><span>google.protobuf, 3.11.3</span></li><li><span>hdf.pinvoke.1.10, 1.10.500</span></li><li><span>methodboundaryaspect.fody, 2.0.138</span></li><li><span>microsoft.extensions.dependencyinjection, 5.0.1</span></li><li><span>microsoft.extensions.dependencyinjection.abstractions, 5.0.0</span></li><li><span>newtonsoft.json, 12.0.3</span></li><li><span>NumSharp, 0.30.0</span></li><li><span>protobuf.text, 0.5.0</span></li><li><span>scisharp.keras.hdf5, 1.1.10.500</span></li><li><span>SciSharp.TensorFlow.Redist, 2.5.0</span></li><li><span>serilog, 2.5.0</span></li><li><span>serilog.sinks.console, 3.1.1</span></li><li><span>sharpziplib, 1.3.1</span></li><li><span>system.resources.extensions, 5.0.0</span></li><li><span>TensorFlow.Keras, 0.5.1</span></li><li><span>TensorFlow.Net, 0.40.1</span></li></ul></div><div></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: TensorFlow.Net\"\n",
    "#r \"nuget: TensorFlow.Keras\"\n",
    "#r \"nuget: SciSharp.TensorFlow.Redist\"\n",
    "#r \"nuget: NumSharp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using System.Collections.Generic;\n",
    "using Tensorflow;\n",
    "using Tensorflow.Keras;\n",
    "using static Tensorflow.Binding;\n",
    "using static Tensorflow.KerasApi;\n",
    "using Tensorflow.Keras.Utils;\n",
    "using System.IO;\n",
    "using Tensorflow.Keras.Engine;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "tf.enable_eager_execution();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// string fileName = \"flower_photos.tgz\";\n",
    "// string url = $\"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\";\n",
    "// string data_dir = Path.Combine(Path.GetTempPath(), \"flower_photos\");\n",
    "// Web.Download(url, data_dir, fileName);\n",
    "// Compress.ExtractTGZ(Path.Join(data_dir, fileName), data_dir);\n",
    "// data_dir = Path.Combine(data_dir, \"flower_photos\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "int batch_size = 32;\n",
    "int epochs = 3;\n",
    "var img_dim = (64, 64);\n",
    "IDatasetV2 train_ds, val_ds;\n",
    "Model model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 429 files belonging to 3 classes.\n",
      "Using 343 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = keras.preprocessing.image_dataset_from_directory(@\"datasets/mlnet/starwars\",\n",
    "    validation_split: 0.2f,\n",
    "    subset: \"training\",\n",
    "   // seed: 123,\n",
    "    image_size: img_dim,\n",
    "    batch_size: batch_size);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 429 files belonging to 3 classes.\n",
      "Using 86 files for validation.\n"
     ]
    }
   ],
   "source": [
    " val_ds = keras.preprocessing.image_dataset_from_directory(@\"datasets/mlnet/starwars\",\n",
    "    validation_split: 0.2f,\n",
    "    subset: \"validation\",\n",
    "  //  seed: 123,\n",
    "    image_size: img_dim,\n",
    "    batch_size: batch_size);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.shuffle(1000).prefetch(buffer_size: -1);\n",
    "val_ds = val_ds.prefetch(buffer_size: -1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images: System.Int32[] \n",
      "labels: [1, 1, 2, 2, 1, ..., 2, 0, 2, 2, 0] \n",
      "images: System.Int32[] \n",
      "labels: [0, 1, 1, 0, 1, ..., 0, 1, 0, 1, 2] \n",
      "images: System.Int32[] \n",
      "labels: [2, 2, 1, 0, 2, ..., 1, 1, 1, 2, 2] \n",
      "images: System.Int32[] \n",
      "labels: [2, 0, 1, 0, 0, ..., 1, 0, 1, 2, 0] \n",
      "images: System.Int32[] \n",
      "labels: [1, 1, 1, 2, 0, ..., 2, 0, 0, 2, 2] \n",
      "images: System.Int32[] \n",
      "labels: [2, 0, 2, 0, 0, ..., 0, 0, 0, 1, 2] \n",
      "images: System.Int32[] \n",
      "labels: [1, 2, 0, 1, 0, ..., 0, 1, 1, 1, 2] \n",
      "images: System.Int32[] \n",
      "labels: [1, 0, 0, 0, 2, ..., 0, 0, 2, 1, 0] \n",
      "images: System.Int32[] \n",
      "labels: [2, 2, 2, 1, 2, ..., 2, 1, 2, 1, 1] \n",
      "images: System.Int32[] \n",
      "labels: [1, 2, 2, 1, 2, ..., 2, 1, 2, 0, 2] \n",
      "images: System.Int32[] \n",
      "labels: [0, 0, 1, 1, 2, ..., 1, 0, 0, 1, 2] \n"
     ]
    }
   ],
   "source": [
    "foreach (var (img, label) in train_ds)\n",
    "{\n",
    "    print($\"images: {img.shape}\");\n",
    "    print($\"labels: {label.numpy()}\");\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: sequential \n",
      "_________________________________________________________________ \n",
      "Layer (type)                  Output Shape              Param #   \n",
      "================================================================= \n",
      "rescaling_input (InputLayer)  (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________ \n",
      "rescaling (Rescaling)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________ \n",
      "conv2d (Conv2D)               (None, 64, 64, 16)        448       \n",
      "_________________________________________________________________ \n",
      "max_pooling2d (MaxPooling2D)  (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________ \n",
      "flatten (Flatten)             (None, 16384)             0         \n",
      "_________________________________________________________________ \n",
      "dense (Dense)                 (None, 128)               2097280   \n",
      "_________________________________________________________________ \n",
      "dense_1 (Dense)               (None, 3)                 387       \n",
      "================================================================= \n",
      "Total params: 2098115 \n",
      "Trainable params: 2098115 \n",
      "Non-trainable params: 0 \n",
      "_________________________________________________________________ \n"
     ]
    }
   ],
   "source": [
    "int num_classes = 3;\n",
    "// var normalization_layer = tf.keras.layers.Rescaling(1.0f / 255);\n",
    "var layers = keras.layers;\n",
    "model = keras.Sequential(new List<ILayer>\n",
    "{\n",
    "    layers.Rescaling(1.0f / 255, input_shape: (64, 64, 3)),\n",
    "    layers.Conv2D(16, 3, padding: \"same\", activation: keras.activations.Relu),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation: keras.activations.Relu),\n",
    "    layers.Dense(num_classes)\n",
    "});\n",
    "\n",
    "model.compile(optimizer: keras.optimizers.Adam(),\n",
    "loss: keras.losses.SparseCategoricalCrossentropy(from_logits: true),\n",
    "metrics: new[] { \"accuracy\" });\n",
    "\n",
    "model.summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/003, Step: 0001/0011, loss: 1.116969, accuracy: 0.437500\n",
      "Epoch: 001/003, Step: 0002/0011, loss: 3.850616, accuracy: 0.328125\n",
      "Epoch: 001/003, Step: 0003/0011, loss: 4.077186, accuracy: 0.312500\n",
      "Epoch: 001/003, Step: 0004/0011, loss: 3.505513, accuracy: 0.320312\n",
      "Epoch: 001/003, Step: 0005/0011, loss: 3.149244, accuracy: 0.343750\n",
      "Epoch: 001/003, Step: 0006/0011, loss: 2.953929, accuracy: 0.338542\n",
      "Epoch: 001/003, Step: 0007/0011, loss: 2.853076, accuracy: 0.312500\n",
      "Epoch: 001/003, Step: 0008/0011, loss: 2.785301, accuracy: 0.319838\n",
      "Epoch: 001/003, Step: 0009/0011, loss: 2.621889, accuracy: 0.336918\n",
      "Epoch: 001/003, Step: 0010/0011, loss: 2.462848, accuracy: 0.356913\n",
      "Epoch: 001/003, Step: 0011/0011, loss: 2.377858, accuracy: 0.344023\n"
     ]
    },
    {
     "ename": "Unhandled exception",
     "evalue": "Tensorflow.TensorflowException: ; No such file or directory\n\t [[{{node ReadFile}}]]\n   at Tensorflow.Eager.EagerRunner.TFE_FastPathExecute(FastPathOpExecInfo op_exec_info)\n   at Tensorflow.Contexts.Context.<>c__DisplayClass51_0.<ExecuteOp>b__1()\n   at Tensorflow.Contexts.Context.ExecuteOp(String OpType, String Name, ExecuteOpArgs args)\n   at Tensorflow.dataset_ops.iterator_get_next(Tensor iterator, TF_DataType[] output_types, TensorShape[] output_shapes, String name)\n   at Tensorflow.OwnedIterator.next()\n   at Tensorflow.Keras.Engine.Model.train_step_function(OwnedIterator iterator)\n   at Tensorflow.Keras.Engine.Model.FitInternal(Int32 epochs, Int32 verbose)\n   at Tensorflow.Keras.Engine.Model.fit(IDatasetV2 dataset, IDatasetV2 validation_data, Int32 batch_size, Int32 epochs, Int32 verbose, Single validation_split, Boolean shuffle, Int32 initial_epoch, Int32 max_queue_size, Int32 workers, Boolean use_multiprocessing)\n   at Submission#16.<<Initialize>>d__0.MoveNext()\n--- End of stack trace from previous location ---\n   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)",
     "output_type": "error",
     "traceback": [
      "Tensorflow.TensorflowException: ; No such file or directory\n\t [[{{node ReadFile}}]]\n   at Tensorflow.Eager.EagerRunner.TFE_FastPathExecute(FastPathOpExecInfo op_exec_info)\n   at Tensorflow.Contexts.Context.<>c__DisplayClass51_0.<ExecuteOp>b__1()\n   at Tensorflow.Contexts.Context.ExecuteOp(String OpType, String Name, ExecuteOpArgs args)\n   at Tensorflow.dataset_ops.iterator_get_next(Tensor iterator, TF_DataType[] output_types, TensorShape[] output_shapes, String name)\n   at Tensorflow.OwnedIterator.next()\n   at Tensorflow.Keras.Engine.Model.train_step_function(OwnedIterator iterator)\n   at Tensorflow.Keras.Engine.Model.FitInternal(Int32 epochs, Int32 verbose)\n   at Tensorflow.Keras.Engine.Model.fit(IDatasetV2 dataset, IDatasetV2 validation_data, Int32 batch_size, Int32 epochs, Int32 verbose, Single validation_split, Boolean shuffle, Int32 initial_epoch, Int32 max_queue_size, Int32 workers, Boolean use_multiprocessing)\n   at Submission#16.<<Initialize>>d__0.MoveNext()\n--- End of stack trace from previous location ---\n   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)",
      "   at Tensorflow.Eager.EagerRunner.TFE_FastPathExecute(FastPathOpExecInfo op_exec_info)",
      "   at Tensorflow.Contexts.Context.<>c__DisplayClass51_0.<ExecuteOp>b__1()",
      "   at Tensorflow.Contexts.Context.ExecuteOp(String OpType, String Name, ExecuteOpArgs args)",
      "   at Tensorflow.dataset_ops.iterator_get_next(Tensor iterator, TF_DataType[] output_types, TensorShape[] output_shapes, String name)",
      "   at Tensorflow.OwnedIterator.next()",
      "   at Tensorflow.Keras.Engine.Model.train_step_function(OwnedIterator iterator)",
      "   at Tensorflow.Keras.Engine.Model.FitInternal(Int32 epochs, Int32 verbose)",
      "   at Tensorflow.Keras.Engine.Model.fit(IDatasetV2 dataset, IDatasetV2 validation_data, Int32 batch_size, Int32 epochs, Int32 verbose, Single validation_split, Boolean shuffle, Int32 initial_epoch, Int32 max_queue_size, Int32 workers, Boolean use_multiprocessing)",
      "   at Submission#16.<<Initialize>>d__0.MoveNext()",
      "--- End of stack trace from previous location ---",
      "   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)"
     ]
    }
   ],
   "source": [
    "model.fit(train_ds, validation_data: val_ds, epochs: epochs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "file_extension": ".cs",
   "mimetype": "text/x-csharp",
   "name": "C#",
   "pygments_lexer": "csharp",
   "version": "9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
