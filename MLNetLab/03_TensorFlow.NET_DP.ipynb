{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#r \"nuget: TensorFlow.Net\"\r\n",
    "#r \"nuget: TensorFlow.Keras\"\r\n",
    "#r \"nuget: SciSharp.TensorFlow.Redist\"\r\n",
    "#r \"nuget: NumSharp\""
   ],
   "outputs": [],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **深度学习** #"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "using System.Linq;\r\n",
    "using Tensorflow;\r\n",
    "using Tensorflow.Keras.Optimizers;\r\n",
    "using Tensorflow.NumPy;\r\n",
    "using static Tensorflow.Binding;\r\n",
    "using static Tensorflow.KerasApi;\r\n"
   ],
   "outputs": [],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "int num_classes = 10; \r\n",
    "int num_features = 784; \r\n",
    "\r\n",
    "float learning_rate = 0.001f;\r\n",
    "int training_steps = 1000;\r\n",
    "int batch_size = 256;\r\n",
    "int display_step = 100;\r\n",
    "\r\n",
    "int n_hidden_1 = 128; // 1st layer number of neurons.\r\n",
    "int n_hidden_2 = 256; // 2nd layer number of neurons.\r\n",
    "\r\n",
    "IDatasetV2 train_data;\r\n",
    "NDArray x_test, y_test, x_train, y_train;\r\n",
    "IVariableV1 h1, h2, wout, b1, b2, bout;\r\n",
    "float accuracy_test = 0f;"
   ],
   "outputs": [],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.enable_eager_execution();"
   ],
   "outputs": [],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "((x_train, y_train), (x_test, y_test)) = keras.datasets.mnist.load_data();\r\n",
    "(x_train, x_test) = (x_train.reshape((-1, num_features)), x_test.reshape((-1, num_features)));\r\n",
    "\r\n",
    "(x_train, x_test) = (x_train / 255f, x_test / 255f);\r\n",
    "\r\n",
    "train_data = tf.data.Dataset.from_tensor_slices(x_train, y_train);\r\n",
    "train_data = train_data.repeat()\r\n",
    "    .shuffle(5000)\r\n",
    "    .batch(batch_size)\r\n",
    "    .prefetch(1)\r\n",
    "    .take(training_steps);"
   ],
   "outputs": [],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "var random_normal = tf.initializers.random_normal_initializer();\r\n",
    "h1 = tf.Variable(random_normal.Apply(new InitializerArgs((num_features, n_hidden_1))));\r\n",
    "h2 = tf.Variable(random_normal.Apply(new InitializerArgs((n_hidden_1, n_hidden_2))));\r\n",
    "wout = tf.Variable(random_normal.Apply(new InitializerArgs((n_hidden_2, num_classes))));\r\n",
    "b1 = tf.Variable(tf.zeros(n_hidden_1));\r\n",
    "b2 = tf.Variable(tf.zeros(n_hidden_2));\r\n",
    "bout = tf.Variable(tf.zeros(num_classes));\r\n",
    "var trainable_variables = new IVariableV1[] { h1, h2, wout, b1, b2, bout };"
   ],
   "outputs": [],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "var optimizer = keras.optimizers.SGD(learning_rate);"
   ],
   "outputs": [],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Tensor neural_net(Tensor x)\r\n",
    "{\r\n",
    "    var layer_1 = tf.add(tf.matmul(x, h1.AsTensor()), b1.AsTensor());\r\n",
    "    layer_1 = tf.nn.sigmoid(layer_1);\r\n",
    "    var layer_2 = tf.add(tf.matmul(layer_1, h2.AsTensor()), b2.AsTensor());\r\n",
    "    layer_2 = tf.nn.sigmoid(layer_2);\r\n",
    "    var out_layer = tf.matmul(layer_2, wout.AsTensor()) + bout.AsTensor();\r\n",
    "    return tf.nn.softmax(out_layer);\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Tensor accuracy(Tensor y_pred, Tensor y_true)\r\n",
    "{\r\n",
    "    var correct_prediction = tf.equal(tf.math.argmax(y_pred, 1), tf.cast(y_true, tf.int64));\r\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis: -1);\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Tensor cross_entropy(Tensor y_pred, Tensor y_true)\r\n",
    "{\r\n",
    "    y_true = tf.one_hot(y_true, depth: num_classes);\r\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-9f, 1.0f);\r\n",
    "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred)));\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "void run_optimization(OptimizerV2 optimizer, Tensor x, Tensor y, IVariableV1[] trainable_variables)\r\n",
    "{\r\n",
    "    using var g = tf.GradientTape();\r\n",
    "    var pred = neural_net(x);\r\n",
    "    var loss = cross_entropy(pred, y);\r\n",
    "\r\n",
    "    var gradients = g.gradient(loss, trainable_variables);\r\n",
    "\r\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables.Select(x => x as ResourceVariable)));\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "foreach (var (step, (batch_x, batch_y)) in enumerate(train_data, 1))\r\n",
    "{\r\n",
    "    run_optimization(optimizer, batch_x, batch_y, trainable_variables);\r\n",
    "\r\n",
    "    if (step % display_step == 0)\r\n",
    "    {\r\n",
    "        var pred = neural_net(batch_x);\r\n",
    "        var loss = cross_entropy(pred, batch_y);\r\n",
    "        var acc = accuracy(pred, batch_y);\r\n",
    "        print($\"step: {step}, loss: {(float)loss}, accuracy: {(float)acc}\");\r\n",
    "    }\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "var pred = neural_net(x_test);\r\n",
    "accuracy_test = (float)accuracy(pred, y_test);\r\n",
    "print($\"Test Accuracy: {accuracy_test}\");"
   ],
   "outputs": [],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "file_extension": ".cs",
   "mimetype": "text/x-csharp",
   "name": "C#",
   "pygments_lexer": "csharp",
   "version": "9.0"
  },
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}