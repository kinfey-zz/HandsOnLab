{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#r \"nuget: TensorFlow.Net\"\n",
    "#r \"nuget: TensorFlow.Keras\"\n",
    "#r \"nuget: SciSharp.TensorFlow.Redist\"\n",
    "#r \"nuget: NumSharp\""
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>NumSharp, 0.30.0</span></li><li><span>SciSharp.TensorFlow.Redist, 2.5.0</span></li><li><span>TensorFlow.Keras, 0.6.0</span></li><li><span>TensorFlow.Net, 0.60.0</span></li></ul></div></div>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **线性回归** #"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Tensorflow.NET 和Tensorflow 是一致的** ###"
   ],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "var train_X = np.array(3.3f, 4.4f, 5.5f, 6.71f, 6.93f, 4.168f, 9.779f, 6.182f, 7.59f, 2.167f,\n",
    "    7.042f, 10.791f, 5.313f, 7.997f, 5.654f, 9.27f, 3.1f);\n",
    "var train_Y = np.array(1.7f, 2.76f, 2.09f, 3.19f, 1.694f, 1.573f, 3.366f, 2.596f, 2.53f, 1.221f,\n",
    "    2.827f, 3.465f, 1.65f, 2.904f, 2.42f, 2.94f, 1.3f);\n",
    "var n_samples = (int)train_X.shape[0];\n",
    "\n",
    "int display_step = 50;\n",
    "\n",
    "float learning_rate = 0.01f;\n",
    "\n",
    "int training_epochs = 1000;"
   ],
   "outputs": [],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.compat.v1.disable_eager_execution();"
   ],
   "outputs": [],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "var pred = tf.add(tf.multiply(X, W), b);\n",
    "\n",
    "var cost = tf.reduce_sum(tf.pow(pred - Y, 2.0f)) / (2.0f * n_samples);\n",
    "\n",
    " var optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost);\n",
    "\n",
    "var init = tf.global_variables_initializer();"
   ],
   "outputs": [],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "var sess = tf.Session();\n",
    "// Run the initializer\n",
    "sess.run(init);"
   ],
   "outputs": [],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for (int epoch = 0; epoch < training_epochs; epoch++)\n",
    "{\n",
    "    foreach (var (x, y) in zip<float>(train_X, train_Y))\n",
    "        sess.run(optimizer, (X, x), (Y, y));\n",
    "\n",
    "                // Display logs per epoch step\n",
    "    if ((epoch + 1) % display_step == 0)\n",
    "    {\n",
    "        var c = sess.run(cost, (X, train_X), (Y, train_Y));\n",
    "        Console.WriteLine($\"Epoch: {epoch + 1} cost={c} \" + $\"W={sess.run(W)} b={sess.run(b)}\");\n",
    "    }\n",
    "}"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 50 cost=0.19328241 W=0.44026902 b=-0.57023937\n",
      "Epoch: 100 cost=0.17984506 W=0.42892876 b=-0.48865774\n",
      "Epoch: 150 cost=0.16795948 W=0.41826284 b=-0.41192815\n",
      "Epoch: 200 cost=0.15744655 W=0.40823138 b=-0.33976227\n",
      "Epoch: 250 cost=0.14814776 W=0.39879647 b=-0.27188826\n",
      "Epoch: 300 cost=0.13992295 W=0.38992265 b=-0.208051\n",
      "Epoch: 350 cost=0.13264813 W=0.38157663 b=-0.14801025\n",
      "Epoch: 400 cost=0.12621354 W=0.373727 b=-0.09154031\n",
      "Epoch: 450 cost=0.12052226 W=0.36634418 b=-0.038428996\n",
      "Epoch: 500 cost=0.11548846 W=0.35940045 b=0.011523556\n",
      "Epoch: 550 cost=0.111036174 W=0.35286975 b=0.058505252\n",
      "Epoch: 600 cost=0.107098304 W=0.34672746 b=0.102692656\n",
      "Epoch: 650 cost=0.10361542 W=0.34095046 b=0.14425191\n",
      "Epoch: 700 cost=0.10053498 W=0.335517 b=0.18333974\n",
      "Epoch: 750 cost=0.09781052 W=0.3304067 b=0.22010279\n",
      "Epoch: 800 cost=0.09540092 W=0.32560027 b=0.25467926\n",
      "Epoch: 850 cost=0.09326982 W=0.32107988 b=0.28719908\n",
      "Epoch: 900 cost=0.09138502 W=0.3168282 b=0.31778553\n",
      "Epoch: 950 cost=0.089718156 W=0.31282943 b=0.34655213\n",
      "Epoch: 1000 cost=0.08824395 W=0.30906853 b=0.37360826\n"
     ]
    }
   ],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "var training_cost = sess.run(cost, (X, train_X), (Y, train_Y));\n",
    "Console.WriteLine($\"Training cost={training_cost} W={sess.run(W)} b={sess.run(b)}\");"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training cost=0.08824395 W=0.30906853 b=0.37360826\n"
     ]
    }
   ],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "var test_X = np.array(6.83f, 4.668f, 8.9f, 7.91f, 5.7f, 8.7f, 3.1f, 2.1f);\n",
    "var test_Y = np.array(1.84f, 2.273f, 3.2f, 2.831f, 2.92f, 3.24f, 1.35f, 1.03f);\n",
    "Console.WriteLine(\"Testing... (Mean square loss Comparison)\");\n",
    "var testing_cost = sess.run(tf.reduce_sum(tf.pow(pred - Y, 2.0f)) / (2.0f * test_X.shape[0]),(X, test_X), (Y, test_Y));\n",
    "Console.WriteLine($\"Testing cost={testing_cost}\");\n",
    "var diff = Math.Abs((float)training_cost - (float)testing_cost);\n",
    "Console.WriteLine($\"Absolute mean square loss difference: {diff}\");"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Testing... (Mean square loss Comparison)\n",
      "Testing cost=0.07984468\n",
      "Absolute mean square loss difference: 0.008399263\n"
     ]
    }
   ],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "using Tensorflow.NumPy;\n",
    "using static Tensorflow.Binding;\n",
    "using static Tensorflow.KerasApi;"
   ],
   "outputs": [],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_X = np.array(3.3f, 4.4f, 5.5f, 6.71f, 6.93f, 4.168f, 9.779f, 6.182f, \n",
    "    7.59f, 2.167f, 7.042f, 10.791f, 5.313f, 7.997f, 5.654f, 9.27f, 3.1f);\n",
    "\n",
    "train_Y = np.array(1.7f, 2.76f, 2.09f, 3.19f, 1.694f, 1.573f, 3.366f, \n",
    "    2.596f, 2.53f, 1.221f, 2.827f, 3.465f, 1.65f, 2.904f, 2.42f, 2.94f, 1.3f);"
   ],
   "outputs": [],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.enable_eager_execution();"
   ],
   "outputs": [],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "var layers = keras.layers;\n",
    "var inputs = keras.Input(shape: 1);\n",
    "var outputs = layers.Dense(1).Apply(inputs);\n",
    "var model = keras.Model(inputs, outputs);"
   ],
   "outputs": [],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.summary();"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: functional_1 \n",
      "_________________________________________________________________ \n",
      "Layer (type)                  Output Shape              Param #   \n",
      "================================================================= \n",
      "input_2 (InputLayer)          (None, 1)                 0         \n",
      "_________________________________________________________________ \n",
      "dense_1 (Dense)               (None, 1)                 2         \n",
      "================================================================= \n",
      "Total params: 2 \n",
      "Trainable params: 2 \n",
      "Non-trainable params: 0 \n",
      "_________________________________________________________________ \n"
     ]
    }
   ],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    " model.compile(loss: keras.losses.MeanSquaredError(),\n",
    "    optimizer: keras.optimizers.SGD(0.005f),\n",
    "     metrics: new[] { \"acc\" });"
   ],
   "outputs": [],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    " model.fit(train_X, train_Y, epochs: 100);"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 001/100, Step: 0001/0001, loss: 191.550079, acc: 0.000000\n",
      "Epoch: 002/100, Step: 0001/0001, loss: 57.735706, acc: 0.000000\n",
      "Epoch: 003/100, Step: 0001/0001, loss: 17.493158, acc: 0.000000\n",
      "Epoch: 004/100, Step: 0001/0001, loss: 5.390812, acc: 0.000000\n",
      "Epoch: 005/100, Step: 0001/0001, loss: 1.751174, acc: 0.000000\n",
      "Epoch: 006/100, Step: 0001/0001, loss: 0.656559, acc: 0.000000\n",
      "Epoch: 007/100, Step: 0001/0001, loss: 0.327316, acc: 0.000000\n",
      "Epoch: 008/100, Step: 0001/0001, loss: 0.228248, acc: 0.000000\n",
      "Epoch: 009/100, Step: 0001/0001, loss: 0.198401, acc: 0.000000\n",
      "Epoch: 010/100, Step: 0001/0001, loss: 0.189371, acc: 0.000000\n",
      "Epoch: 011/100, Step: 0001/0001, loss: 0.186602, acc: 0.000000\n",
      "Epoch: 012/100, Step: 0001/0001, loss: 0.185716, acc: 0.000000\n",
      "Epoch: 013/100, Step: 0001/0001, loss: 0.185396, acc: 0.000000\n",
      "Epoch: 014/100, Step: 0001/0001, loss: 0.185246, acc: 0.000000\n",
      "Epoch: 015/100, Step: 0001/0001, loss: 0.185148, acc: 0.000000\n",
      "Epoch: 016/100, Step: 0001/0001, loss: 0.185066, acc: 0.000000\n",
      "Epoch: 017/100, Step: 0001/0001, loss: 0.184988, acc: 0.000000\n",
      "Epoch: 018/100, Step: 0001/0001, loss: 0.184912, acc: 0.000000\n",
      "Epoch: 019/100, Step: 0001/0001, loss: 0.184836, acc: 0.000000\n",
      "Epoch: 020/100, Step: 0001/0001, loss: 0.184761, acc: 0.000000\n",
      "Epoch: 021/100, Step: 0001/0001, loss: 0.184686, acc: 0.000000\n",
      "Epoch: 022/100, Step: 0001/0001, loss: 0.184611, acc: 0.000000\n",
      "Epoch: 023/100, Step: 0001/0001, loss: 0.184537, acc: 0.000000\n",
      "Epoch: 024/100, Step: 0001/0001, loss: 0.184462, acc: 0.000000\n",
      "Epoch: 025/100, Step: 0001/0001, loss: 0.184388, acc: 0.000000\n",
      "Epoch: 026/100, Step: 0001/0001, loss: 0.184314, acc: 0.000000\n",
      "Epoch: 027/100, Step: 0001/0001, loss: 0.184240, acc: 0.000000\n",
      "Epoch: 028/100, Step: 0001/0001, loss: 0.184166, acc: 0.000000\n",
      "Epoch: 029/100, Step: 0001/0001, loss: 0.184093, acc: 0.000000\n",
      "Epoch: 030/100, Step: 0001/0001, loss: 0.184019, acc: 0.000000\n",
      "Epoch: 031/100, Step: 0001/0001, loss: 0.183946, acc: 0.000000\n",
      "Epoch: 032/100, Step: 0001/0001, loss: 0.183873, acc: 0.000000\n",
      "Epoch: 033/100, Step: 0001/0001, loss: 0.183800, acc: 0.000000\n",
      "Epoch: 034/100, Step: 0001/0001, loss: 0.183728, acc: 0.000000\n",
      "Epoch: 035/100, Step: 0001/0001, loss: 0.183655, acc: 0.000000\n",
      "Epoch: 036/100, Step: 0001/0001, loss: 0.183583, acc: 0.000000\n",
      "Epoch: 037/100, Step: 0001/0001, loss: 0.183511, acc: 0.000000\n",
      "Epoch: 038/100, Step: 0001/0001, loss: 0.183439, acc: 0.000000\n",
      "Epoch: 039/100, Step: 0001/0001, loss: 0.183367, acc: 0.000000\n",
      "Epoch: 040/100, Step: 0001/0001, loss: 0.183296, acc: 0.000000\n",
      "Epoch: 041/100, Step: 0001/0001, loss: 0.183224, acc: 0.000000\n",
      "Epoch: 042/100, Step: 0001/0001, loss: 0.183153, acc: 0.000000\n",
      "Epoch: 043/100, Step: 0001/0001, loss: 0.183082, acc: 0.000000\n",
      "Epoch: 044/100, Step: 0001/0001, loss: 0.183011, acc: 0.000000\n",
      "Epoch: 045/100, Step: 0001/0001, loss: 0.182940, acc: 0.000000\n",
      "Epoch: 046/100, Step: 0001/0001, loss: 0.182870, acc: 0.000000\n",
      "Epoch: 047/100, Step: 0001/0001, loss: 0.182799, acc: 0.000000\n",
      "Epoch: 048/100, Step: 0001/0001, loss: 0.182729, acc: 0.000000\n",
      "Epoch: 049/100, Step: 0001/0001, loss: 0.182659, acc: 0.000000\n",
      "Epoch: 050/100, Step: 0001/0001, loss: 0.182589, acc: 0.000000\n",
      "Epoch: 051/100, Step: 0001/0001, loss: 0.182519, acc: 0.000000\n",
      "Epoch: 052/100, Step: 0001/0001, loss: 0.182450, acc: 0.000000\n",
      "Epoch: 053/100, Step: 0001/0001, loss: 0.182381, acc: 0.000000\n",
      "Epoch: 054/100, Step: 0001/0001, loss: 0.182311, acc: 0.000000\n",
      "Epoch: 055/100, Step: 0001/0001, loss: 0.182242, acc: 0.000000\n",
      "Epoch: 056/100, Step: 0001/0001, loss: 0.182173, acc: 0.000000\n",
      "Epoch: 057/100, Step: 0001/0001, loss: 0.182105, acc: 0.000000\n",
      "Epoch: 058/100, Step: 0001/0001, loss: 0.182036, acc: 0.000000\n",
      "Epoch: 059/100, Step: 0001/0001, loss: 0.181968, acc: 0.000000\n",
      "Epoch: 060/100, Step: 0001/0001, loss: 0.181900, acc: 0.000000\n",
      "Epoch: 061/100, Step: 0001/0001, loss: 0.181832, acc: 0.000000\n",
      "Epoch: 062/100, Step: 0001/0001, loss: 0.181764, acc: 0.000000\n",
      "Epoch: 063/100, Step: 0001/0001, loss: 0.181696, acc: 0.000000\n",
      "Epoch: 064/100, Step: 0001/0001, loss: 0.181628, acc: 0.000000\n",
      "Epoch: 065/100, Step: 0001/0001, loss: 0.181561, acc: 0.000000\n",
      "Epoch: 066/100, Step: 0001/0001, loss: 0.181494, acc: 0.000000\n",
      "Epoch: 067/100, Step: 0001/0001, loss: 0.181427, acc: 0.000000\n",
      "Epoch: 068/100, Step: 0001/0001, loss: 0.181360, acc: 0.000000\n",
      "Epoch: 069/100, Step: 0001/0001, loss: 0.181293, acc: 0.000000\n",
      "Epoch: 070/100, Step: 0001/0001, loss: 0.181227, acc: 0.000000\n",
      "Epoch: 071/100, Step: 0001/0001, loss: 0.181160, acc: 0.000000\n",
      "Epoch: 072/100, Step: 0001/0001, loss: 0.181094, acc: 0.000000\n",
      "Epoch: 073/100, Step: 0001/0001, loss: 0.181028, acc: 0.000000\n",
      "Epoch: 074/100, Step: 0001/0001, loss: 0.180962, acc: 0.000000\n",
      "Epoch: 075/100, Step: 0001/0001, loss: 0.180896, acc: 0.000000\n",
      "Epoch: 076/100, Step: 0001/0001, loss: 0.180831, acc: 0.000000\n",
      "Epoch: 077/100, Step: 0001/0001, loss: 0.180765, acc: 0.000000\n",
      "Epoch: 078/100, Step: 0001/0001, loss: 0.180700, acc: 0.000000\n",
      "Epoch: 079/100, Step: 0001/0001, loss: 0.180635, acc: 0.000000\n",
      "Epoch: 080/100, Step: 0001/0001, loss: 0.180570, acc: 0.000000\n",
      "Epoch: 081/100, Step: 0001/0001, loss: 0.180505, acc: 0.000000\n",
      "Epoch: 082/100, Step: 0001/0001, loss: 0.180440, acc: 0.000000\n",
      "Epoch: 083/100, Step: 0001/0001, loss: 0.180376, acc: 0.000000\n",
      "Epoch: 084/100, Step: 0001/0001, loss: 0.180312, acc: 0.000000\n",
      "Epoch: 085/100, Step: 0001/0001, loss: 0.180247, acc: 0.000000\n",
      "Epoch: 086/100, Step: 0001/0001, loss: 0.180183, acc: 0.000000\n",
      "Epoch: 087/100, Step: 0001/0001, loss: 0.180119, acc: 0.000000\n",
      "Epoch: 088/100, Step: 0001/0001, loss: 0.180056, acc: 0.000000\n",
      "Epoch: 089/100, Step: 0001/0001, loss: 0.179992, acc: 0.000000\n",
      "Epoch: 090/100, Step: 0001/0001, loss: 0.179929, acc: 0.000000\n",
      "Epoch: 091/100, Step: 0001/0001, loss: 0.179865, acc: 0.000000\n",
      "Epoch: 092/100, Step: 0001/0001, loss: 0.179802, acc: 0.000000\n",
      "Epoch: 093/100, Step: 0001/0001, loss: 0.179739, acc: 0.000000\n",
      "Epoch: 094/100, Step: 0001/0001, loss: 0.179677, acc: 0.000000\n",
      "Epoch: 095/100, Step: 0001/0001, loss: 0.179614, acc: 0.000000\n",
      "Epoch: 096/100, Step: 0001/0001, loss: 0.179552, acc: 0.000000\n",
      "Epoch: 097/100, Step: 0001/0001, loss: 0.179489, acc: 0.000000\n",
      "Epoch: 098/100, Step: 0001/0001, loss: 0.179427, acc: 0.000000\n",
      "Epoch: 099/100, Step: 0001/0001, loss: 0.179365, acc: 0.000000\n",
      "Epoch: 100/100, Step: 0001/0001, loss: 0.179303, acc: 0.000000\n"
     ]
    }
   ],
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "file_extension": ".cs",
   "mimetype": "text/x-csharp",
   "name": "C#",
   "pygments_lexer": "csharp",
   "version": "9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}